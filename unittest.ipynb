{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import Application as ap\n",
    "\n",
    "import unittest\n",
    "from unittest.mock import patch, MagicMock\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestRestaurantDataProcessor(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        Prepare resources for tests.\n",
    "        \"\"\"\n",
    "        self.url = \"https://raw.githubusercontent.com/Papagoat/brain-assessment/main/restaurant_data.json\"\n",
    "        self.country_code_file = \"country_codes.csv\"\n",
    "        self.output_file_path = \"processed_restaurants.csv\"\n",
    "        self.processor = ap.RestaurantDataProcessor(self.url, self.country_code_file, self.output_file_path)\n",
    "\n",
    "    def test_fetch_json_data(self):\n",
    "        \"\"\"\n",
    "        Test fetching JSON data from an API.\n",
    "        \"\"\"\n",
    "        with patch('requests.get') as mock_get:\n",
    "            # Mocking a successful API response\n",
    "            mock_response = MagicMock()\n",
    "            mock_response.ok = True\n",
    "            mock_response.json.return_value = {\"restaurants\": []}\n",
    "            mock_get.return_value = mock_response\n",
    "\n",
    "            # Testing successful data fetch\n",
    "            result = self.processor.fetch_json_data()\n",
    "            self.assertIsNotNone(result)\n",
    "            mock_get.assert_called_once_with(self.url)\n",
    "\n",
    "            # Mocking an unsuccessful API response and testing failure handling\n",
    "            mock_response.ok = False\n",
    "            result = self.processor.fetch_json_data()\n",
    "            self.assertIsNone(result)\n",
    "\n",
    "    def test_read_country_code_data(self):\n",
    "        \"\"\"\n",
    "        Test reading country code data from a CSV file.\n",
    "        \"\"\"\n",
    "        with patch('pandas.read_csv') as mock_read_csv:\n",
    "            # Mocking successful CSV file read\n",
    "            mock_read_csv.return_value = pd.DataFrame(data={\"Country Code\": [1], \"Country\": [\"India\"]})\n",
    "            result = self.processor.read_country_code_data()\n",
    "            self.assertIsNotNone(result)\n",
    "            mock_read_csv.assert_called_once_with(self.country_code_file)\n",
    "\n",
    "            # Mocking FileNotFoundError to test error handling\n",
    "            mock_read_csv.side_effect = FileNotFoundError\n",
    "            result = self.processor.read_country_code_data()\n",
    "            self.assertIsNone(result)\n",
    "\n",
    "    def test_merge_data(self):\n",
    "        \"\"\"\n",
    "        Test merging JSON data with CSV country code data.\n",
    "        \"\"\"\n",
    "        parsed_data = {\"restaurants\": [{\"restaurant\": {\"location\": {\"country_id\": 1}}}]}\n",
    "        country_code_df = pd.DataFrame(data={\"Country Code\": [1], \"Country\": [\"India\"]})\n",
    "        result = self.processor.merge_data(parsed_data, country_code_df)\n",
    "        self.assertIn(\"Country\", result.columns)  # Check if 'Country' column is in the merged DataFrame\n",
    "\n",
    "    def test_process_merged_data(self):\n",
    "        \"\"\"\n",
    "        Test processing of the merged DataFrame.\n",
    "        \"\"\"\n",
    "        merged_df = pd.DataFrame(data={\n",
    "            \"restaurant.R.res_id\": [1],\n",
    "            \"restaurant.name\": [\"Test Restaurant\"],\n",
    "            \"Country\": [\"India\"],\n",
    "            \"restaurant.location.city\": [\"Test City\"],\n",
    "            \"restaurant.user_rating.votes\": [100],\n",
    "            \"restaurant.user_rating.aggregate_rating\": [\"4.5\"],\n",
    "            \"restaurant.cuisines\": [\"Indian\"]\n",
    "        })\n",
    "        result = self.processor.process_merged_data(merged_df)\n",
    "        self.assertIn(\"Restaurant Name\", result.columns)  # Checking for column renaming\n",
    "        self.assertTrue(result[\"User Aggregate Rating\"].dtype == float)  # Checking data type conversion\n",
    "\n",
    "    def test_export_df_to_csv(self):\n",
    "        \"\"\"\n",
    "        Test exporting a DataFrame to a CSV file.\n",
    "        \"\"\"\n",
    "        with patch('pandas.DataFrame.to_csv') as mock_to_csv:\n",
    "            df = pd.DataFrame()\n",
    "            self.processor.export_df_to_csv(df)\n",
    "            mock_to_csv.assert_called_once_with(self.output_file_path, index=False)\n",
    "\n",
    "    def test_run(self):\n",
    "        \"\"\"\n",
    "        Test the complete data processing workflow.\n",
    "        \"\"\"\n",
    "        # Mocking all methods called within the run method\n",
    "        with patch.object(self.processor, 'fetch_json_data') as mock_fetch, \\\n",
    "             patch.object(self.processor, 'read_country_code_data') as mock_read, \\\n",
    "             patch.object(self.processor, 'merge_data') as mock_merge, \\\n",
    "             patch.object(self.processor, 'process_merged_data') as mock_process, \\\n",
    "             patch.object(self.processor, 'export_df_to_csv') as mock_export:\n",
    "                \n",
    "            # Setting return values for mocked methods\n",
    "            mock_fetch.return_value = {\"restaurants\": []}\n",
    "            mock_read.return_value = pd.DataFrame()\n",
    "            mock_merge.return_value = pd.DataFrame()\n",
    "            mock_process.return_value = pd.DataFrame()\n",
    "\n",
    "            self.processor.run()\n",
    "\n",
    "            # Verifying that each method was called once\n",
    "            mock_fetch.assert_called_once()\n",
    "            mock_read.assert_called_once()\n",
    "            mock_merge.assert_called_once()\n",
    "            mock_process.assert_called_once()\n",
    "            mock_export.assert_called_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestEventDataProcessor(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        Prepare resources for each test.\n",
    "        \"\"\"\n",
    "        self.dummy_df = pd.DataFrame({\n",
    "            \"restaurant.zomato_events\": [[{\"event\": {\"event_id\": 1}}]]\n",
    "        })\n",
    "        self.processor = ap.EventDataProcessor(self.dummy_df, 2021, 12, \"output.csv\")\n",
    "\n",
    "    def test_expand_and_normalize_events(self):\n",
    "        \"\"\"\n",
    "        Test expanding and normalizing events data.\n",
    "        \"\"\"\n",
    "        # Patch the DataFrame's explode method and the json_normalize function\n",
    "        with patch('pandas.DataFrame.explode') as mock_explode, \\\n",
    "             patch('pandas.json_normalize') as mock_json_normalize:\n",
    "            mock_explode.return_value = self.dummy_df  # Mock the result of explode\n",
    "            mock_json_normalize.return_value = pd.DataFrame({\"event.event_id\": [1]})  # Mock the result of json_normalize\n",
    "\n",
    "            result_df = self.processor.expand_and_normalize_events()\n",
    "\n",
    "            # Verify that explode and json_normalize were called as expected\n",
    "            mock_explode.assert_called_once_with(\"restaurant.zomato_events\")\n",
    "            mock_json_normalize.assert_called_once()\n",
    "            # Ensure the resulting DataFrame has the expected column from normalization\n",
    "            self.assertIn(\"event.event_id\", result_df.columns)\n",
    "\n",
    "    def test_filter_events_by_date(self):\n",
    "        \"\"\"\n",
    "        Test filtering events by date.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Setup a mock DataFrame to filter\n",
    "        events_df = pd.DataFrame({\n",
    "            \"event.start_date\": [\"2019-03-01\", \"2019-05-01\"],\n",
    "            \"event.end_date\": [\"2019-05-31\", \"2020-01-01\"]\n",
    "        })\n",
    "\n",
    "        filtered_df = self.processor.filter_events_by_date(events_df, 2019, 4)\n",
    "\n",
    "        expected_df = pd.DataFrame({\n",
    "            \"event.start_date\": [\"2019-03-01\"],\n",
    "            \"event.end_date\": [\"2019-03-01\"]\n",
    "        })\n",
    "\n",
    "        pd.testing.assert_frame_equal(filtered_df.reset_index(drop=True), expected_df)\n",
    "\n",
    "    def test_process_events_data(self):\n",
    "        \"\"\"\n",
    "        Test processing of events data.\n",
    "        \"\"\"\n",
    "        # Patch the internal methods used in the process_events_data method\n",
    "        with patch.object(self.processor, 'expand_and_normalize_events', return_value=pd.DataFrame()) as mock_expand, \\\n",
    "             patch.object(self.processor, 'filter_events_by_date', return_value=pd.DataFrame()) as mock_filter:\n",
    "\n",
    "            self.processor.process_events_data()\n",
    "\n",
    "            # Verify that each method was called once as part of the data processing workflow\n",
    "            mock_expand.assert_called_once()\n",
    "            mock_filter.assert_called_once()\n",
    "\n",
    "    def test_export_events_to_csv(self):\n",
    "        \"\"\"\n",
    "        Test exporting events data to CSV.\n",
    "        \"\"\"\n",
    "        # Patch the to_csv method of DataFrame\n",
    "        with patch('pandas.DataFrame.to_csv') as mock_to_csv:\n",
    "            df_to_export = pd.DataFrame({\"event.event_id\": [1]})\n",
    "\n",
    "            self.processor.export_events_to_csv(df_to_export, \"output.csv\")\n",
    "\n",
    "            # Verify that to_csv was called with the correct arguments\n",
    "            mock_to_csv.assert_called_once_with(\"output.csv\", index=False)\n",
    "\n",
    "    def test_run(self):\n",
    "        \"\"\"\n",
    "        Test the full run method orchestrating the events data processing.\n",
    "        \"\"\"\n",
    "        # Patch the methods called within the run method\n",
    "        with patch.object(self.processor, 'process_events_data', return_value=pd.DataFrame()) as mock_process, \\\n",
    "             patch.object(self.processor, 'export_events_to_csv') as mock_export:\n",
    "\n",
    "            self.processor.run()\n",
    "\n",
    "            # Verify that the process and export methods are each called once\n",
    "            mock_process.assert_called_once()\n",
    "            mock_export.assert_called_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestRatingStatisticsProcessor(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        Prepare resources for each test.\n",
    "        \n",
    "        Initializes a RatingStatisticsProcessor instance with a dummy DataFrame and a test output path.\n",
    "        \"\"\"\n",
    "        self.dummy_df = pd.DataFrame({\n",
    "            \"restaurant.user_rating.rating_text\": [\"Excellent\", \"Good\", \"Average\"],\n",
    "            \"restaurant.user_rating.aggregate_rating\": [\"4.5\", \"3.5\", \"2.5\"]\n",
    "        })\n",
    "        self.output_file_path = \"test_output.json\"\n",
    "        self.processor = ap.RatingStatisticsProcessor(self.dummy_df, self.output_file_path)\n",
    "\n",
    "    def test_filter_and_convert_ratings(self):\n",
    "        \"\"\"\n",
    "        Test filtering by specified rating texts and conversion of rating to float.\n",
    "        \n",
    "        Ensures that the DataFrame is correctly filtered and ratings are converted to float.\n",
    "        \"\"\"\n",
    "        specified_texts =  [\"Excellent\",\"Very Good\", \"Good\", \"Average\", \"Poor\"]\n",
    "        result_df = self.processor.filter_and_convert_ratings(specified_texts)\n",
    "\n",
    "        # Verify that only rows with specified rating texts are present\n",
    "        self.assertTrue(all(result_df['restaurant.user_rating.rating_text'].isin(specified_texts)))\n",
    "        # Check if ratings are converted to float\n",
    "        self.assertTrue(pd.api.types.is_float_dtype(result_df['restaurant.user_rating.aggregate_rating']))\n",
    "\n",
    "    def test_analyze_rating_distribution(self):\n",
    "        \"\"\"\n",
    "        Test analysis of rating distribution.\n",
    "        \n",
    "        Checks that the method returns a DataFrame with correct aggregation of ratings.\n",
    "        \"\"\"\n",
    "        filtered_df = self.processor.filter_and_convert_ratings([\"Excellent\", \"Good\"])\n",
    "        result_statistics = self.processor.analyze_rating_distribution(filtered_df)\n",
    "\n",
    "        # Verify the structure and content of the result DataFrame\n",
    "        self.assertIn(\"min\", result_statistics.columns)\n",
    "        self.assertIn(\"max\", result_statistics.columns)\n",
    "\n",
    "    def test_export_to_json(self):\n",
    "        \"\"\"\n",
    "        Test exporting rating statistics to a JSON file.\n",
    "        \n",
    "        Verifies that the method attempts to write to the specified file path.\n",
    "        \"\"\"\n",
    "        # Mock DataFrame to test export\n",
    "        rating_statistics = pd.DataFrame({\n",
    "            \"User Rating\": [\"Excellent\",\"Very Good\", \"Good\", \"Average\", \"Poor\"],\n",
    "            \"min\": [4.0, 3.0,2.0,1.0,0.0],\n",
    "            \"max\": [5.0, 4.0, 3.0,2.0,1.0]\n",
    "        })\n",
    "\n",
    "        with patch('pandas.DataFrame.to_json') as mock_to_json:\n",
    "            self.processor.export_to_json(rating_statistics)\n",
    "\n",
    "            # Verify that to_json was called with the correct file path\n",
    "            mock_to_json.assert_called_once_with(self.output_file_path, orient='records')\n",
    "\n",
    "    def test_run(self):\n",
    "        \"\"\"\n",
    "        Test the full run method orchestrating the rating statistics processing.\n",
    "        \n",
    "        Verifies that the process correctly filters, analyzes, and exports rating data.\n",
    "        \"\"\"\n",
    "        # Patch the internal methods to isolate the run method's workflow\n",
    "        with patch.object(self.processor, 'filter_and_convert_ratings', return_value=pd.DataFrame()) as mock_filter, \\\n",
    "             patch.object(self.processor, 'analyze_rating_distribution', return_value=pd.DataFrame()) as mock_analyze, \\\n",
    "             patch.object(self.processor, 'export_to_json') as mock_export:\n",
    "\n",
    "            self.processor.run([\"Excellent\",\"Very Good\", \"Good\", \"Average\", \"Poor\"])\n",
    "\n",
    "            # Verify that each method in the workflow is called once\n",
    "            mock_filter.assert_called_once()\n",
    "            mock_analyze.assert_called_once()\n",
    "            mock_export.assert_called_once()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_expand_and_normalize_events (__main__.TestEventDataProcessor.test_expand_and_normalize_events)\n",
      "Test expanding and normalizing events data. ... ok\n",
      "test_export_events_to_csv (__main__.TestEventDataProcessor.test_export_events_to_csv)\n",
      "Test exporting events data to CSV. ... ok\n",
      "test_process_events_data (__main__.TestEventDataProcessor.test_process_events_data)\n",
      "Test processing of events data. ... ERROR\n",
      "test_run (__main__.TestEventDataProcessor.test_run)\n",
      "Test the full run method orchestrating the events data processing. ... ok\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_process_events_data (__main__.TestEventDataProcessor.test_process_events_data)\n",
      "Test processing of events data.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\junke\\AppData\\Local\\Temp\\ipykernel_26608\\1689022256.py\", line 55, in test_process_events_data\n",
      "    self.processor.process_events_data()\n",
      "  File \"Application.ipynb\", line 70, in process_events_data\n",
      "  File \"c:\\Users\\junke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 4096, in __getitem__\n",
      "    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\junke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 6199, in _get_indexer_strict\n",
      "    self._raise_if_missing(keyarr, indexer, axis_name)\n",
      "  File \"c:\\Users\\junke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 6248, in _raise_if_missing\n",
      "    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n",
      "KeyError: \"None of [Index(['event.event_id', 'restaurant.id', 'restaurant.name',\\n       'restaurant.photos_url', 'event.title', 'event.start_date',\\n       'event.end_date'],\\n      dtype='object')] are in the [columns]\"\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.033s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events data exported successfully to output.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=1 failures=0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = unittest.TestLoader()\n",
    "suite = unittest.TestSuite()\n",
    "\n",
    "# Add tests to the test suite\n",
    "suite.addTests(loader.loadTestsFromTestCase(TestEventDataProcessor))\n",
    "# Run the test suite\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tests from the TestStringMethods class\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
