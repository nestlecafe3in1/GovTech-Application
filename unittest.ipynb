{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter # Module to import Jupyter Notebook File\n",
    "import Application as ap # File containing main code\n",
    "\n",
    "import unittest\n",
    "from unittest.mock import patch, MagicMock\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestRestaurantDataProcessor(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        Prepare resources for tests.\n",
    "        \"\"\"\n",
    "        self.url = \"https://raw.githubusercontent.com/Papagoat/brain-assessment/main/restaurant_data.json\"\n",
    "        self.country_code_file = \"country_code.csv\"\n",
    "        self.output_file_path = \"processed_restaurants.csv\"\n",
    "        self.processor = ap.RestaurantDataProcessor(self.url, self.country_code_file, self.output_file_path)\n",
    "\n",
    "    def test_fetch_json_data(self):\n",
    "        \"\"\"\n",
    "        Test fetching JSON data from URL\n",
    "        \"\"\"\n",
    "        with patch('requests.get') as mock_get:\n",
    "            # Mocking a successful API response\n",
    "            mock_response = MagicMock()\n",
    "            mock_response.ok = True\n",
    "            mock_response.json.return_value = {\"restaurants\": []}\n",
    "            mock_get.return_value = mock_response\n",
    "\n",
    "            # Testing successful data fetch\n",
    "            result = self.processor.fetch_json_data()\n",
    "            self.assertIsNotNone(result)\n",
    "            mock_get.assert_called_once_with(self.url)\n",
    "\n",
    "            # Mocking an unsuccessful response and testing failure handling\n",
    "            mock_response.ok = False\n",
    "            result = self.processor.fetch_json_data()\n",
    "            self.assertIsNone(result)\n",
    "\n",
    "    def test_read_country_code_data(self):\n",
    "        \"\"\"\n",
    "        Test reading country code data from a CSV file.\n",
    "        \"\"\"\n",
    "        with patch('pandas.read_csv') as mock_read_csv:\n",
    "            # Mocking successful CSV file read\n",
    "            mock_read_csv.return_value = pd.DataFrame(data={\"Country Code\": [1], \"Country\": [\"India\"]})\n",
    "            result = self.processor.read_country_code_data()\n",
    "            self.assertIsNotNone(result)\n",
    "            mock_read_csv.assert_called_once_with(self.country_code_file)\n",
    "\n",
    "            # Mocking FileNotFoundError to test error handling\n",
    "            mock_read_csv.side_effect = FileNotFoundError\n",
    "            result = self.processor.read_country_code_data()\n",
    "            self.assertIsNone(result)\n",
    "\n",
    "    def test_merge_data(self):\n",
    "        \"\"\"\n",
    "        Test merging JSON data with country code data.\n",
    "        \"\"\"\n",
    "        # Mock parsed data\n",
    "        parsed_data = {\n",
    "            \"restaurants\": [\n",
    "                {\"name\": \"Restaurant A\", \"restaurant.location.country_id\": 1, \"cuisine\": \"Italian\"},\n",
    "                {\"name\": \"Restaurant B\", \"restaurant.location.country_id\": 2, \"cuisine\": \"French\"}\n",
    "            ]\n",
    "        }\n",
    "        # Mock country code df\n",
    "        country_code_df = pd.DataFrame({\n",
    "            \"Country Code\": [1, 2],\n",
    "            \"Country Name\": [\"Italy\", \"France\"]\n",
    "        })\n",
    "\n",
    "        merged_df = self.processor.merge_data(parsed_data, country_code_df)\n",
    "\n",
    "        # Check if the merged DataFrame has the expected columns\n",
    "        expected_columns = [\"name\", \"restaurant.location.country_id\", \"cuisine\", \n",
    "                            \"Country Code\", \"Country Name\"\n",
    "                            ]\n",
    "        # Check if merged df missing one or more expected columns\n",
    "        self.assertTrue(all(column in merged_df.columns for column in expected_columns))\n",
    "\n",
    "        # Verify that the merge operation is correct by checking individual rows\n",
    "        self.assertEqual(merged_df.loc[0, \"Country Name\"], \"Italy\")\n",
    "        self.assertEqual(merged_df.loc[1, \"Country Name\"], \"France\")\n",
    "\n",
    "        # Check the size of df \n",
    "        self.assertEqual(len(merged_df), 2)\n",
    "\n",
    "    def test_process_merged_data(self):\n",
    "        \"\"\"\n",
    "        Test processing of the merged DataFrame.\n",
    "        \"\"\"\n",
    "        merged_df = pd.DataFrame({\n",
    "            'restaurant.R.res_id': [1, 2, None],\n",
    "            'restaurant.name': ['Restaurant A', 'Restaurant B', None],\n",
    "            'Country': ['Country A', 'Country B', 'Country C'],\n",
    "            'restaurant.location.city': ['City A', 'City B', 'City C'],\n",
    "            'restaurant.user_rating.votes': [100, 200, 300],\n",
    "            'restaurant.user_rating.aggregate_rating': ['4.5', '3.5', '4'],\n",
    "            'restaurant.cuisines': ['Cuisine A', 'Cuisine B', 'Cuisine C']\n",
    "        })\n",
    "        result = self.processor.process_merged_data(merged_df)\n",
    "\n",
    "        # Expected columns after processing\n",
    "        expected_columns = ['Restaurant Id', 'Restaurant Name', 'Country', 'City', \n",
    "                            'User Rating Votes', 'User Aggregate Rating', 'Cuisines']\n",
    "\n",
    "        # Check that the processed DataFrame has the correct columns\n",
    "        self.assertListEqual(list(result.columns), expected_columns)\n",
    "        # Check that there are no missing values in the DataFrame\n",
    "        self.assertFalse(result.isnull().values.any())\n",
    "        # Checking data type conversion\n",
    "        self.assertTrue(result[\"User Aggregate Rating\"].dtype == float)  \n",
    "\n",
    "    def test_export_df_to_csv(self):\n",
    "        \"\"\"\n",
    "        Test exporting df to a CSV file\n",
    "        \"\"\"\n",
    "        with patch('pandas.DataFrame.to_csv') as mock_to_csv:\n",
    "            df = pd.DataFrame()\n",
    "            self.processor.export_df_to_csv(df)\n",
    "            mock_to_csv.assert_called_once_with(self.output_file_path, index=False)\n",
    "\n",
    "    def test_run(self):\n",
    "        \"\"\"\n",
    "        Test the complete data processing workflow\n",
    "        \"\"\"\n",
    "        # Mocking all methods called within the run method\n",
    "        with patch.object(self.processor, 'fetch_json_data') as mock_fetch, \\\n",
    "             patch.object(self.processor, 'read_country_code_data') as mock_read, \\\n",
    "             patch.object(self.processor, 'merge_data') as mock_merge, \\\n",
    "             patch.object(self.processor, 'process_merged_data') as mock_process, \\\n",
    "             patch.object(self.processor, 'export_df_to_csv') as mock_export:\n",
    "                \n",
    "            # Setting return values for mocked methods\n",
    "            mock_fetch.return_value = {\"restaurants\": []}\n",
    "            mock_read.return_value = pd.DataFrame()\n",
    "            mock_merge.return_value = pd.DataFrame()\n",
    "            mock_process.return_value = pd.DataFrame()\n",
    "\n",
    "            self.processor.run()\n",
    "\n",
    "            # Verifying that each method was called once\n",
    "            mock_fetch.assert_called_once()\n",
    "            mock_read.assert_called_once()\n",
    "            mock_merge.assert_called_once()\n",
    "            mock_process.assert_called_once()\n",
    "            mock_export.assert_called_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestEventDataProcessor(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.dummy_df = pd.DataFrame({\n",
    "            \"restaurant.zomato_events\": [[{\"event\": {\"event_id\": 1}}]]\n",
    "        })\n",
    "        # Initialize class\n",
    "        self.processor = ap.EventDataProcessor(self.dummy_df, 2021, 12, \"output.csv\")\n",
    "\n",
    "    def test_expand_and_normalize_events(self):\n",
    "        \"\"\"\n",
    "        Test expanding and normalizing events data.\n",
    "        \"\"\"\n",
    "        # Patch the DataFrame's explode method and the json_normalize function\n",
    "        with patch('pandas.DataFrame.explode') as mock_explode, \\\n",
    "             patch('pandas.json_normalize') as mock_json_normalize:\n",
    "            mock_explode.return_value = self.dummy_df  # Mock the result of explode\n",
    "            mock_json_normalize.return_value = pd.DataFrame({\"event.event_id\": [1]})  # Mock the result of json_normalize\n",
    "\n",
    "            result_df = self.processor.expand_and_normalize_events()\n",
    "\n",
    "            # Verify that explode and json_normalize were called as expected\n",
    "            mock_explode.assert_called_once_with(\"restaurant.zomato_events\")\n",
    "            mock_json_normalize.assert_called_once()\n",
    "            # Ensure the resulting DataFrame has the expected column from normalization\n",
    "            self.assertIn(\"event.event_id\", result_df.columns)\n",
    "\n",
    "    def test_filter_events_by_date(self):\n",
    "        \"\"\"\n",
    "        Test filtering events by date to include events active in April 2019.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Setup a mock DataFrame to filter\n",
    "        events_df = pd.DataFrame({\n",
    "            \"event.start_date\": [\"2019-03-01\", \"2019-05-01\"],\n",
    "            \"event.end_date\": [\"2019-05-31\", \"2020-01-01\"]\n",
    "        })\n",
    "\n",
    "        filtered_df = self.processor.filter_events_by_date(events_df, 2019, 4)\n",
    "\n",
    "        # Adjust the expected DataFrame to match the correct filtering outcome\n",
    "        expected_df = pd.DataFrame({\n",
    "            \"event.start_date\": pd.to_datetime([\"2019-03-01\"]),\n",
    "            \"event.end_date\": pd.to_datetime([\"2019-05-31\"])\n",
    "        })\n",
    "\n",
    "        # Compare the filtered result with the expected DataFrame\n",
    "        pd.testing.assert_frame_equal(filtered_df.reset_index(drop=True), expected_df.reset_index(drop=True), check_dtype=True)\n",
    "\n",
    "    def test_process_events_data(self):\n",
    "        \"\"\"\n",
    "        Test processing of events data.\n",
    "        \"\"\"\n",
    "        # Patch the internal methods used in the process_events_data method\n",
    "        filtered_df = pd.DataFrame({\n",
    "            \"event.event_id\": [1], \n",
    "            \"restaurant.id\": [101], \n",
    "            \"restaurant.name\": [\"Test Restaurant\"], \n",
    "            \"restaurant.photos_url\": [\"http://example.com/photo.jpg\"], \n",
    "            \"event.title\": [\"Test Event\"], \n",
    "            \"event.start_date\": [\"2021-01-01\"], \n",
    "            \"event.end_date\": [\"2021-01-02\"]\n",
    "        })\n",
    "\n",
    "        # Simulate the final expected DataFrame structure after processing\n",
    "        expected_df = pd.DataFrame({\n",
    "            \"Event Id\": [1], \n",
    "            \"Restaurant Id\": [101], \n",
    "            \"Restaurant Name\": [\"Test Restaurant\"], \n",
    "            \"Photo URL\": [\"http://example.com/photo.jpg\"], \n",
    "            \"Event Title\": [\"Test Event\"],  \n",
    "            \"Event Start Date\": [\"2021-01-01\"],\n",
    "            \"Event End Date\": [\"2021-01-02\"]\n",
    "        })\n",
    "\n",
    "        with patch.object(self.processor, 'expand_and_normalize_events', return_value=pd.DataFrame()) as mock_expand, \\\n",
    "             patch.object(self.processor, 'filter_events_by_date', return_value=filtered_df) as mock_filter:\n",
    "\n",
    "            result_df = self.processor.process_events_data()\n",
    "\n",
    "            # Verify that each method was called once as part of the data processing workflow\n",
    "            mock_expand.assert_called_once()\n",
    "            mock_filter.assert_called_once()\n",
    "            \n",
    "            # Compare dataframes to check if renaming of columns have worked\n",
    "            pd.testing.assert_frame_equal(result_df, expected_df)\n",
    "\n",
    "\n",
    "\n",
    "    def test_export_events_to_csv(self):\n",
    "        \"\"\"\n",
    "        Test exporting events data to CSV.\n",
    "        \"\"\"\n",
    "        # Patch the to_csv method of DataFrame\n",
    "        with patch('pandas.DataFrame.to_csv') as mock_to_csv:\n",
    "            df_to_export = pd.DataFrame({\"event.event_id\": [1]})\n",
    "\n",
    "            self.processor.export_events_to_csv(df_to_export, \"output.csv\")\n",
    "\n",
    "            # Verify that to_csv was called with the correct arguments\n",
    "            mock_to_csv.assert_called_once_with(\"output.csv\", index=False)\n",
    "\n",
    "    def test_run(self):\n",
    "        \"\"\"\n",
    "        Test the full run method orchestrating the events data processing.\n",
    "        \"\"\"\n",
    "        # Patch the methods called within the run method\n",
    "        with patch.object(self.processor, 'process_events_data', return_value=pd.DataFrame()) as mock_process, \\\n",
    "             patch.object(self.processor, 'export_events_to_csv') as mock_export:\n",
    "\n",
    "            self.processor.run()\n",
    "\n",
    "            # Verify that the process and export methods are each called once\n",
    "            mock_process.assert_called_once()\n",
    "            mock_export.assert_called_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestRatingStatisticsProcessor(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        Initialize RatingStatisticsProcessor instance with a dummy DataFrame and a test output path.\n",
    "        \"\"\"\n",
    "        self.dummy_df = pd.DataFrame({\n",
    "            'restaurant.user_rating.rating_text': ['Excellent', 'Good', 'Average', 'Poor', 'Excellent', 'Good', \"WRONG\"],\n",
    "            'restaurant.user_rating.aggregate_rating': [\"4.5\", '4.0', '3.0', '2.0',' 5.0', '4.2', '1.0']\n",
    "            })\n",
    "        self.output_file_path = \"test_output.json\"\n",
    "        self.processor = ap.RatingStatisticsProcessor(self.dummy_df, self.output_file_path)\n",
    "\n",
    "    def test_filter_and_convert_ratings(self):\n",
    "        \"\"\"\n",
    "        Test filtering by specified rating texts and conversion of rating to float.\n",
    "        \"\"\"\n",
    "\n",
    "        specified_texts =  [\"Excellent\",\"Good\", \"Average\"]\n",
    "        result_df = self.processor.filter_and_convert_ratings(specified_texts)\n",
    "\n",
    "        # Verify that only rows with specified rating texts are present\n",
    "        self.assertTrue(all(\n",
    "            result_df['restaurant.user_rating.rating_text'].isin(specified_texts)\n",
    "            ))\n",
    "\n",
    "    def test_analyze_rating_distribution(self):\n",
    "        \"\"\"\n",
    "        Test analysis of rating distribution.\n",
    "        \n",
    "        Checks that the method returns a DataFrame with correct aggregation of ratings.\n",
    "        \"\"\"\n",
    "        filtered_df = self.processor.filter_and_convert_ratings([\"Excellent\", \"Good\"])\n",
    "        result_statistics = self.processor.analyze_rating_distribution(filtered_df)\n",
    "\n",
    "        # Verify the structure and content of the result DataFrame\n",
    "        self.assertIn(\"min\", result_statistics.columns)\n",
    "        self.assertIn(\"max\", result_statistics.columns)\n",
    "\n",
    "    def test_export_to_json(self):\n",
    "        \"\"\"\n",
    "        Test exporting rating statistics to a JSON file.\n",
    "        \n",
    "        Verifies that the method attempts to write to the specified file path.\n",
    "        \"\"\"\n",
    "        # Mock DataFrame to test export\n",
    "        rating_statistics = pd.DataFrame({\n",
    "            \"User Rating\": [\"Excellent\",\"Very Good\", \"Good\", \"Average\", \"Poor\"],\n",
    "            \"min\": [4.0, 3.0,2.0,1.0,0.0],\n",
    "            \"max\": [5.0, 4.0, 3.0,2.0,1.0]\n",
    "        })\n",
    "\n",
    "        with patch('pandas.DataFrame.to_json') as mock_to_json:\n",
    "            self.processor.export_to_json(rating_statistics)\n",
    "\n",
    "            # Verify that to_json was called with the correct file path\n",
    "            mock_to_json.assert_called_once_with(self.output_file_path, orient='records')\n",
    "\n",
    "    def test_run(self):\n",
    "        \"\"\"\n",
    "        Test the full run method orchestrating the rating statistics processing.\n",
    "        \n",
    "        Verifies that the process correctly filters, analyzes, and exports rating data.\n",
    "        \"\"\"\n",
    "        # Patch the internal methods to isolate the run method's workflow\n",
    "        with patch.object(self.processor, 'filter_and_convert_ratings', return_value=pd.DataFrame()) as mock_filter, \\\n",
    "             patch.object(self.processor, 'analyze_rating_distribution', return_value=pd.DataFrame()) as mock_analyze, \\\n",
    "             patch.object(self.processor, 'export_to_json') as mock_export:\n",
    "\n",
    "            self.processor.run([\"Excellent\",\"Very Good\", \"Good\", \"Average\", \"Poor\"])\n",
    "\n",
    "            # Verify that each method in the workflow is called once\n",
    "            mock_filter.assert_called_once()\n",
    "            mock_analyze.assert_called_once()\n",
    "            mock_export.assert_called_once()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:1049: ImportWarning: NotebookFinder.find_spec() not found; falling back to find_module()\n",
      ".<frozen importlib._bootstrap>:1049: ImportWarning: NotebookFinder.find_spec() not found; falling back to find_module()\n",
      ".....<frozen importlib._bootstrap>:1049: ImportWarning: NotebookFinder.find_spec() not found; falling back to find_module()\n",
      "...<frozen importlib._bootstrap>:1049: ImportWarning: NotebookFinder.find_spec() not found; falling back to find_module()\n",
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 15 tests in 0.034s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events data exported successfully to output.csv\n",
      "Rating statistics exported successfully\n",
      "Restaurant Data exported successfully to processed_restaurants.csv\n",
      "Error reading country code file: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x236472c6790>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
