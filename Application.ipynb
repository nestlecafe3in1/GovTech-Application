{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\junke\\AppData\\Local\\Temp\\ipykernel_22180\\913430442.py:1: DeprecationWarning: \n","Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n","(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n","but was not found to be installed on your system.\n","If this would cause problems for you,\n","please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n","        \n","  import pandas as pd\n"]}],"source":["import pandas as pd\n","import json\n","import requests\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class RestaurantDataProcessor:\n","    def __init__(self, url, country_code_file, output_file_path):\n","        \"\"\"\n","        Initializes the RestaurantDataProcessor with URLs and file paths.\n","        \n","        param url: URL to fetch restaurant JSON data.\n","        param country_code_file: Path to the CSV file containing country codes.\n","        param output_file_path: Path where the processed CSV data will be saved.\n","        \"\"\"\n","        self.url = url\n","        self.country_code_file = country_code_file\n","        self.output_file_path = output_file_path\n","        self.main_restaurant_df = None \n","\n","    def fetch_json_data(self):\n","        \"\"\"\n","        Fetches JSON data from the specified URL.\n","\n","        return: Parsed JSON data or None if an error occurs.\n","        \"\"\"\n","        \n","        response = requests.get(self.url)\n","        if response.ok:\n","            return response.json()\n","        else: \n","            return None\n","\n","    def read_country_code_data(self):\n","        \"\"\"\n","        Reads country code data from a CSV file.\n","\n","        return: DataFrame containing country code data or None if file not found.\n","        \"\"\"\n","        try:\n","            return pd.read_csv(self.country_code_file)\n","        except FileNotFoundError as e:\n","            print(f\"Error reading country code file: {e}\")\n","            return None\n","\n","    def merge_data(self, parsed_data, country_code_df):\n","        \"\"\"\n","        Merges restaurant JSON data with country code data from the CSV file.\n","\n","        param parsed_data: JSON data containing restaurant information.\n","        param country_code_df: DataFrame containing country codes.\n","        return: Merged DataFrame with restaurant data and country codes.\n","        \"\"\"\n","        self.main_restaurant_df = pd.json_normalize(parsed_data, \"restaurants\")\n","        merged_df = pd.merge(\n","            self.main_restaurant_df, country_code_df, \n","            how='left', left_on='restaurant.location.country_id', \n","            right_on='Country Code'\n","        )\n","        return merged_df\n","\n","    def process_merged_data(self, merged_df):\n","        \"\"\"\n","        Processes the merged DataFrame by extracting, renaming, and cleaning the data.\n","\n","        param merged_df: Merged DataFrame with restaurant and country code data.\n","        return: Processed DataFrame ready for export.\n","        \"\"\"\n","\n","        # Extracts required fields\n","        extract_restaurant_df = merged_df[[\n","            'restaurant.R.res_id', 'restaurant.name', 'Country', \n","            'restaurant.location.city', 'restaurant.user_rating.votes', \n","            'restaurant.user_rating.aggregate_rating', 'restaurant.cuisines'\n","        ]]\n","        \n","        # Dictionary of columns to rename\n","        renamed_columns = {\n","            'restaurant.R.res_id': 'Restaurant Id',\n","            'restaurant.name': 'Restaurant Name',\n","            'restaurant.location.city': 'City',\n","            'restaurant.user_rating.votes': 'User Rating Votes',\n","            'restaurant.user_rating.aggregate_rating': 'User Aggregate Rating',\n","            'restaurant.cuisines': 'Cuisines'\n","        }\n","        \n","        renamed_restaurant_df = extract_restaurant_df.rename(columns=renamed_columns)\n","        renamed_restaurant_df['User Aggregate Rating'] = renamed_restaurant_df['User Aggregate Rating'].astype('float64')\n","        final_restaurant_df = renamed_restaurant_df.dropna()\n","        return final_restaurant_df\n","\n","    def export_df_to_csv(self, df):\n","        \"\"\"\n","        Exports the final DataFrame to a CSV file.\n","\n","        param df: DataFrame to be exported.\n","        \"\"\"\n","        try:\n","            df.to_csv(self.output_file_path, index=False)\n","            print(f\"Restaurant Data exported successfully to {self.output_file_path}\")\n","        except Exception as e:\n","            print(f\"Error exporting data: {e}\")\n","\n","    def run(self):\n","        \"\"\"\n","        Orchestrates the data fetching, processing, and exporting workflow.\n","        \"\"\"\n","\n","        # Fetches json data from url\n","        json_data = self.fetch_json_data()\n","        \n","        if json_data:\n","            country_code_df = self.read_country_code_data()\n","            if country_code_df is not None:\n","                merged_df = self.merge_data(json_data, country_code_df)\n","                final_df = self.process_merged_data(merged_df)\n","                self.export_df_to_csv(final_df)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class EventDataProcessor:\n","    def __init__(self, main_restaurant_df, specified_year, specified_month, output_file_path):\n","        \"\"\"\n","        Initializes the RestaurantEventsProcessor with the main restaurant DataFrame.\n","        param main_restaurant_df: DataFrame containing main restaurant data.\n","        param specified_year: Year to filter the dataset by (in int)\n","        param specified_month: Month to filter the dataset by (in int)\n","        \"\"\"\n","        self.main_restaurant_df = main_restaurant_df\n","        self.specified_year = specified_year\n","        self.specified_month = specified_month\n","        self.output_file_path = output_file_path\n","\n","    def expand_and_normalize_events(self):\n","        \"\"\"\n","        Expands the 'restaurant.zomato_events' column in the DataFrame, normalizing the nested structures.\n","        \"\"\"\n","\n","        # Unpack the lists in the events column vertically\n","        expanded_events_df = self.main_restaurant_df.explode(\"restaurant.zomato_events\")\n","        \n","        # Unpack the dictionaries within each element of the column\n","        unpacked_events_df = pd.json_normalize(expanded_events_df[\"restaurant.zomato_events\"])\n","        \n","        # Reset the index of expanded_events_df\n","        expanded_events_df.reset_index(drop=True, inplace=True)\n","\n","        # Merge the unpacked DataFrame with the original DataFrame (if there are events to merge)\n","        events_df = pd.concat([expanded_events_df, unpacked_events_df], axis=1)\n","        \n","        return events_df\n","\n","    def filter_events_by_date(self, events_df, year, month):\n","        \"\"\"\n","        Filters events based on their start and end dates to include only those relevant to the specified month and year.\n","\n","        param events_df: DataFrame with event data to filter.\n","        param year: Year to filter events by.\n","        param month: Month to filter events by.\n","        return: DataFrame with events filtered by the specified month and year.\n","        \"\"\"\n","        # Ensure event date columns are in datetime format\n","        events_df['event.start_date'] = pd.to_datetime(events_df['event.start_date'])\n","        events_df['event.end_date'] = pd.to_datetime(events_df['event.end_date'])\n","\n","        # Events that start on or before the end of the specified month and year\n","        start_date_condition = (events_df['event.start_date'].dt.year < year) | \\\n","                            ((events_df['event.start_date'].dt.year == year) & (events_df['event.start_date'].dt.month <= month))\n","        # Events that end on or after the start of the specified month and year\n","        end_date_condition = (events_df['event.end_date'].dt.year > year) | \\\n","                            ((events_df['event.end_date'].dt.year == year) & (events_df['event.end_date'].dt.month >= month))\n","\n","        # Apply conditions\n","        filtered_events_df = events_df[start_date_condition & end_date_condition]\n","        \n","        return filtered_events_df\n","\n","    def process_events_data(self):\n","        \"\"\"\n","        Processes event data by expanding, normalizing, filtering by date, and preparing for export.\n","        \"\"\"\n","        events_df = self.expand_and_normalize_events()\n","        filtered_events_df = self.filter_events_by_date(events_df, self.specified_year, self.specified_month)\n","\n","        # Extract and rename required columns\n","        final_columns = [\n","            \"event.event_id\", \"restaurant.id\", \"restaurant.name\", \n","            \"restaurant.photos_url\", \"event.title\", \"event.start_date\", \"event.end_date\"\n","        ]\n","        final_events_df = filtered_events_df[final_columns]\n","\n","        columns_to_rename = {\n","            \"event.event_id\": \"Event Id\", \n","            \"restaurant.id\": \"Restaurant Id\",\n","            \"restaurant.name\": \"Restaurant Name\", \n","            \"restaurant.photos_url\": \"Photo URL\",\n","            \"event.title\": \"Event Title\", \n","            \"event.start_date\": \"Event Start Date\",\n","            \"event.end_date\": \"Event End Date\"\n","        }\n","        \n","        final_events_df = final_events_df.rename(columns=columns_to_rename)\n","        return final_events_df\n","\n","    def export_events_to_csv(self, df, file_path):\n","        \"\"\"\n","        Exports the processed events DataFrame to a CSV file.\n","\n","        param df: DataFrame with the events data to export.\n","        param file_path: Path to save the exported CSV file.\n","        \"\"\"\n","        try:\n","            df.to_csv(file_path, index=False)\n","            print(f\"Events data exported successfully to {file_path}\")\n","        except Exception as e:\n","            print(f\"Error exporting events data: {e}\")\n","\n","    def run(self):\n","        \"\"\"\n","        Orchestrates the processing and exporting of restaurant event data.\n","\n","        param output_file_path: Path where the processed events data CSV will be saved.\n","        \"\"\"\n","        final_events_df = self.process_events_data()\n","        self.export_events_to_csv(final_events_df, self.output_file_path)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class RatingStatisticsProcessor:\n","    def __init__(self, main_restaurant_df, output_file_path):\n","        \"\"\"\n","        Initializes the RatingStatisticsProcessor with the main restaurant DataFrame and the output path for the JSON file.\n","        \n","        param main_restaurant_df: DataFrame containing main restaurant data.\n","        param output_file_path: The path where the rating statistics JSON will be saved.\n","        \"\"\"\n","        self.main_restaurant_df = main_restaurant_df\n","        self.output_file_path = output_file_path\n","\n","    def filter_and_convert_ratings(self, specified_texts):\n","        \"\"\"\n","        Filters the DataFrame for specified rating texts and converts the aggregate rating column to float.\n","        \n","        param specified_texts: List of rating texts to filter by.\n","        return: DataFrame filtered for specified rating texts with aggregate rating as float.\n","        \"\"\"\n","        filtered_df = self.main_restaurant_df[\n","            self.main_restaurant_df['restaurant.user_rating.rating_text'].isin(specified_texts)\n","        ]\n","        filtered_df['restaurant.user_rating.aggregate_rating'] = filtered_df['restaurant.user_rating.aggregate_rating'].astype(\"float64\")\n","        return filtered_df\n","\n","    def analyze_rating_distribution(self, filtered_df):\n","        \"\"\"\n","        Analyzes the distribution of aggregate ratings for each rating text.\n","        \n","        param filtered_df: DataFrame filtered by specified rating texts.\n","        return: DataFrame with the distribution statistics of ratings.\n","        \"\"\"\n","        aggregates = ['min', 'max']\n","        rating_statistics = filtered_df.groupby('restaurant.user_rating.rating_text', as_index=False)['restaurant.user_rating.aggregate_rating'].agg(aggregates)\n","        \n","        # Rename user rating column\n","        rating_statistics = rating_statistics.rename(columns={\"restaurant.user_rating.rating_text\": \"User Rating\"})\n","        return rating_statistics\n","\n","    def export_to_json(self, rating_statistics):\n","        \"\"\"\n","        Exports the rating statistics DataFrame to a JSON file.\n","        \n","        param rating_statistics: DataFrame containing rating statistics.\n","        \"\"\"\n","        try:\n","            rating_statistics.to_json(self.output_file_path, orient='records')\n","            print(f\"Rating statistics exported successfully\")\n","        except Exception as e:\n","            print(f\"Error exporting rating statistics: {e}\")\n","\n","    def run(self, specified_texts):\n","        \"\"\"\n","        Orchestrates the filtering, analysis, and exporting of restaurant rating data.\n","        \n","        param specified_texts: List of rating texts to filter by.\n","        \"\"\"\n","        filtered_df = self.filter_and_convert_ratings(specified_texts)\n","        rating_statistics = self.analyze_rating_distribution(filtered_df)\n","        self.export_to_json(rating_statistics)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Restaurant Data exported successfully to restaurants.csv\n","Events data exported successfully to restaurant_events.csv\n","Rating statistics exported successfully\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\junke\\AppData\\Local\\Temp\\ipykernel_22180\\3893491828.py:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  filtered_df['restaurant.user_rating.aggregate_rating'] = filtered_df['restaurant.user_rating.aggregate_rating'].astype(\"float64\")\n"]}],"source":["if __name__ == \"__main__\":\n","    restaurant_data_url = \"https://raw.githubusercontent.com/Papagoat/brain-assessment/main/restaurant_data.json\"\n","    country_code_file = \"Country-Code.csv\"\n","    restaurants_output_file_path = \"restaurants.csv\"\n","\n","    restaurant_processor = RestaurantDataProcessor(restaurant_data_url, country_code_file, restaurants_output_file_path)\n","    restaurant_processor.run()\n","\n","\n","    # Specified year and month to filter the event dataset (in int)\n","    event_year = 2019\n","    event_month = 4\n","    \n","    events_output_file_path = \"restaurant_events.csv\"\n","\n","    event_processor = EventDataProcessor(restaurant_processor.main_restaurant_df, event_year, event_month, events_output_file_path)\n","    event_processor.run()\n","\n","    statistics_output_file_path = \"restaurant_data.json\"\n","    specified_texts = ['Excellent', 'Very Good', 'Good', 'Average', 'Poor']\n","    \n","    rating_processor = RatingStatisticsProcessor(restaurant_processor.main_restaurant_df, statistics_output_file_path)\n","    rating_processor.run(specified_texts)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":2}
