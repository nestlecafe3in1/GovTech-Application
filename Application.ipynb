{"cells":[{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import json\n","import requests\n","import numpy as np"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["class RestaurantDataProcessor:\n","    def __init__(self, url, country_code_file, output_file_path):\n","        \"\"\"\n","        Initializes the RestaurantDataProcessor with URLs and file paths.\n","        \n","        param url: URL to fetch restaurant JSON data.\n","        param country_code_file: Path to the CSV file containing country codes.\n","        param output_file_path: Path where the processed CSV data will be saved.\n","        \"\"\"\n","        self.url = url\n","        self.country_code_file = country_code_file\n","        self.output_file_path = output_file_path\n","        self.main_restaurant_df = None \n","\n","    def fetch_json_data(self):\n","        \"\"\"\n","        Fetches JSON data from the specified URL.\n","\n","        return: Parsed JSON data or None if an error occurs.\n","        \"\"\"\n","        try:\n","            response = requests.get(self.url)\n","            response.raise_for_status()  # Ensure the request was successful\n","            return response.json()\n","        except requests.exceptions.RequestException as e:\n","            print(f\"Error fetching restaurant data: {e}\")\n","            return None\n","\n","    def read_country_code_data(self):\n","        \"\"\"\n","        Reads country code data from a CSV file.\n","\n","        return: DataFrame containing country code data or None if file not found.\n","        \"\"\"\n","        try:\n","            return pd.read_csv(self.country_code_file)\n","        except FileNotFoundError as e:\n","            print(f\"Error reading country code file: {e}\")\n","            return None\n","\n","    def merge_data(self, parsed_data, country_code_df):\n","        \"\"\"\n","        Merges restaurant JSON data with country code data from the CSV file.\n","\n","        param parsed_data: JSON data containing restaurant information.\n","        param country_code_df: DataFrame containing country codes.\n","        return: Merged DataFrame with restaurant data and country codes.\n","        \"\"\"\n","        self.main_restaurant_df = pd.json_normalize(parsed_data, \"restaurants\")\n","        merged_df = pd.merge(\n","            self.main_restaurant_df, country_code_df, \n","            how='left', left_on='restaurant.location.country_id', \n","            right_on='Country Code'\n","        )\n","        return merged_df\n","\n","    def process_merged_data(self, merged_df):\n","        \"\"\"\n","        Processes the merged DataFrame by extracting, renaming, and cleaning the data.\n","\n","        param merged_df: Merged DataFrame with restaurant and country code data.\n","        return: Processed DataFrame ready for export.\n","        \"\"\"\n","\n","        # Extracts required fields\n","        extract_restaurant_df = merged_df[[\n","            'restaurant.R.res_id', 'restaurant.name', 'Country', \n","            'restaurant.location.city', 'restaurant.user_rating.votes', \n","            'restaurant.user_rating.aggregate_rating', 'restaurant.cuisines'\n","        ]]\n","        \n","        # Dictionary of columns to rename\n","        renamed_columns = {\n","            'restaurant.R.res_id': 'Restaurant Id',\n","            'restaurant.name': 'Restaurant Name',\n","            'restaurant.location.city': 'City',\n","            'restaurant.user_rating.votes': 'User Rating Votes',\n","            'restaurant.user_rating.aggregate_rating': 'User Aggregate Rating',\n","            'restaurant.cuisines': 'Cuisines'\n","        }\n","        \n","        renamed_restaurant_df = extract_restaurant_df.rename(columns=renamed_columns)\n","        renamed_restaurant_df['User Aggregate Rating'] = renamed_restaurant_df['User Aggregate Rating'].astype('float64')\n","        final_restaurant_df = renamed_restaurant_df.dropna()\n","        return final_restaurant_df\n","\n","    def export_df_to_csv(self, df):\n","        \"\"\"\n","        Exports the final DataFrame to a CSV file.\n","\n","        param df: DataFrame to be exported.\n","        \"\"\"\n","        try:\n","            df.to_csv(self.output_file_path, index=False)\n","            print(f\"Restaurant Data exported successfully to {self.output_file_path}\")\n","        except Exception as e:\n","            print(f\"Error exporting data: {e}\")\n","\n","    def run(self):\n","        \"\"\"\n","        Orchestrates the data fetching, processing, and exporting workflow.\n","        \"\"\"\n","\n","        # Fetches json data from url\n","        json_data = self.fetch_json_data()\n","        \n","        if json_data:\n","            country_code_df = self.read_country_code_data()\n","            if country_code_df is not None:\n","                merged_df = self.merge_data(json_data, country_code_df)\n","                final_df = self.process_merged_data(merged_df)\n","                self.export_df_to_csv(final_df)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["class EventDataProcessor:\n","    def __init__(self, main_restaurant_df, specified_year, specified_month, output_file_path):\n","        \"\"\"\n","        Initializes the RestaurantEventsProcessor with the main restaurant DataFrame.\n","        \n","        param main_restaurant_df: DataFrame containing main restaurant data.\n","        param specified_year: Year to filter the dataset by (in int)\n","        param specified_month: Month to filter the dataset by (in int)\n","        \"\"\"\n","        self.main_restaurant_df = main_restaurant_df\n","        self.specified_year = specified_year\n","        self.specified_month = specified_month\n","        self.output_file_path = output_file_path\n","\n","    def expand_and_normalize_events(self):\n","        \"\"\"\n","        Expands the 'restaurant.zomato_events' column in the DataFrame, normalizing the nested structures.\n","        \"\"\"\n","\n","        # Unpack the lists in the events column vertically\n","        expanded_events_df = self.main_restaurant_df.explode(\"restaurant.zomato_events\")\n","        \n","        # Unpack the dictionaries within each element of the column\n","        unpacked_events_df = pd.json_normalize(expanded_events_df[\"restaurant.zomato_events\"])\n","        \n","        # Reset the index of expanded_events_df\n","        expanded_events_df.reset_index(drop=True, inplace=True)\n","\n","        # Merge the unpacked DataFrame with the original DataFrame (if there are events to merge)\n","        events_df = pd.concat([expanded_events_df, unpacked_events_df], axis=1)\n","        \n","        return events_df\n","\n","    def filter_events_by_date(self, events_df, year, month):\n","        \"\"\"\n","        Filters events based on their start and end dates to include only those relevant to the specified month and year.\n","\n","        param events_df: DataFrame with event data to filter.\n","        param year: Year to filter events by.\n","        param month: Month to filter events by.\n","        return: DataFrame with events filtered by the specified month and year.\n","        \"\"\"\n","        # Ensure event date columns are in datetime format\n","        events_df['event.start_date'] = pd.to_datetime(events_df['event.start_date'])\n","        events_df['event.end_date'] = pd.to_datetime(events_df['event.end_date'])\n","\n","        # Events that start on or before the end of the specified month and year\n","        start_date_condition = (events_df['event.start_date'].dt.year < year) | \\\n","                            ((events_df['event.start_date'].dt.year == year) & (events_df['event.start_date'].dt.month <= month))\n","        # Events that end on or after the start of the specified month and year\n","        end_date_condition = (events_df['event.end_date'].dt.year > year) | \\\n","                            ((events_df['event.end_date'].dt.year == year) & (events_df['event.end_date'].dt.month >= month))\n","\n","        # Apply conditions\n","        filtered_events_df = events_df[start_date_condition & end_date_condition]\n","        \n","        return filtered_events_df\n","\n","    def process_events_data(self):\n","        \"\"\"\n","        Processes event data by expanding, normalizing, filtering by date, and preparing for export.\n","        \"\"\"\n","        events_df = self.expand_and_normalize_events()\n","        filtered_events_df = self.filter_events_by_date(events_df, self.specified_year, self.specified_month)\n","\n","        # Extract and rename required columns\n","        final_columns = [\n","            \"event.event_id\", \"restaurant.id\", \"restaurant.name\", \n","            \"restaurant.photos_url\", \"event.title\", \"event.start_date\", \"event.end_date\"\n","        ]\n","        final_events_df = filtered_events_df[final_columns]\n","\n","        columns_to_rename = {\n","            \"event.event_id\": \"Event Id\", \n","            \"restaurant.id\": \"Restaurant Id\",\n","            \"restaurant.name\": \"Restaurant Name\", \n","            \"restaurant.photos_url\": \"Photo URL\",\n","            \"event.title\": \"Event Title\", \n","            \"event.start_date\": \"Event Start Date\",\n","            \"event.end_date\": \"Event End Date\"\n","        }\n","        \n","        final_events_df = final_events_df.rename(columns=columns_to_rename)\n","        return final_events_df\n","\n","    def export_events_to_csv(self, df, file_path):\n","        \"\"\"\n","        Exports the processed events DataFrame to a CSV file.\n","\n","        param df: DataFrame with the events data to export.\n","        param file_path: Path to save the exported CSV file.\n","        \"\"\"\n","        try:\n","            df.to_csv(file_path, index=False)\n","            print(f\"Events data exported successfully to {file_path}\")\n","        except Exception as e:\n","            print(f\"Error exporting events data: {e}\")\n","\n","    def run(self):\n","        \"\"\"\n","        Orchestrates the processing and exporting of restaurant event data.\n","\n","        param output_file_path: Path where the processed events data CSV will be saved.\n","        \"\"\"\n","        final_events_df = self.process_events_data()\n","        self.export_events_to_csv(final_events_df, self.output_file_path)"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Data exported successfully to restaurants.csv\n","Events data exported successfully to restaurant_events.csv\n"]}],"source":["if __name__ == \"__main__\":\n","    restaurant_data_url = \"https://raw.githubusercontent.com/Papagoat/brain-assessment/main/restaurant_data.json\"\n","    country_code_file = \"Country-Code.csv\"\n","    restaurants_output_file_path = \"restaurants.csv\"\n","\n","    restaurant_processor = RestaurantDataProcessor(restaurant_data_url, country_code_file, restaurants_output_file_path)\n","    restaurant_processor.run()\n","\n","\n","    # Specified year and month to filter the event dataset (in int)\n","    event_year = 2019\n","    event_month = 4\n","    \n","    events_output_file_path = \"restaurant_events.csv\"\n","\n","    event_processor = EventDataProcessor(restaurant_processor.main_restaurant_df, event_year, event_month, events_output_file_path)\n","    event_processor.run()"]},{"cell_type":"markdown","metadata":{},"source":["### Part 2"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["\"\"\"\n","Expanding the restaurant.zomato_events column \n","\"\"\"\n","\n","# Unpack the lists in the events column vertically\n","expended_events_df = main_restaurant_df.explode(\"restaurant.zomato_events\")\n","\n","# Unpack the dictionaries within each element of the column\n","unpacked_events_df = pd.json_normalize(expended_events_df[\"restaurant.zomato_events\"])\n","\n","# Merge the unpacked DataFrame with the original DataFrame\n","events_df = pd.concat([main_restaurant_df, unpacked_events_df], axis=1)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["\"\"\"\n","Filtering past event in the month of April 2019 \n","\"\"\"\n","\n","# Change event start and end date to a date data type\n","events_df['event.start_date'] = pd.to_datetime(events_df[\"event.start_date\"])\n","events_df['event.end_date'] = pd.to_datetime(events_df[\"event.end_date\"])\n","\n","\n","# Define the condition for events starting in or before April 2019\n","start_date_condition = (\n","    (events_df['event.start_date'].dt.year == 2019) & \n","    (events_df['event.start_date'].dt.month <= 4)\n",")\n","\n","# Define the condition for events ending in or after April 2019\n","end_date_condition = (\n","    (events_df['event.end_date'].dt.year == 2019) & \n","    (events_df['event.end_date'].dt.month >= 4)\n",")\n","\n","# Apply the conditions to filter the DataFrame\n","April2019_events_df = events_df[(start_date_condition | end_date_condition)]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["\"\"\"\n","Extraction and renaming of required columns\n","\"\"\"\n","\n","# Extract required Columns\n","April2019_events_df = April2019_events_df[[\n","    \"event.event_id\", \"restaurant.id\",\n","    \"restaurant.name\", \"restaurant.photos_url\",\n","    \"event.title\", \"event.start_date\",\n","    \"event.end_date\"\n","    ]]\n","\n","# Rename required columns\n","columns_to_rename = {\n","    \"event.event_id\":\"Event Id\", \n","    \"restaurant.id\":\"Restaurant Id\",\n","    \"restaurant.name\":\"Restaurant Name\", \n","    \"restaurant.photos_url\":\"Photo URL\",\n","    \"event.title\":\"Event Title\", \n","    \"event.start_date\":\"Event Start Date\",\n","    \"event.end_date\":\"Event End Date\"\n","}\n","\n","final_events_df = April2019_events_df.rename(columns=columns_to_rename)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["\"\"\"\n","Export final_events_df to CSV\n","\"\"\"\n","\n","final_events_df.to_csv(input(), index=False)\n","\n","# My input was C:\\\\Users\\\\junke\\\\Desktop\\\\Important Documents (JunKeat)\\\\GovTech-Application\\\\restaurant_events.csv"]},{"cell_type":"markdown","metadata":{},"source":["### Part 3"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["\"\"\"\n","Filter for the specified rating texts only\n","\"\"\"\n","\n","specified_texts = ['Excellent', 'Very Good', 'Good', 'Average', 'Poor']\n","filtered_rating_df = main_restaurant_df[main_restaurant_df['restaurant.user_rating.rating_text'].isin(specified_texts)]"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","To check for null values in the aggregate rating column\"\"\"\n","\n","filtered_rating_df['restaurant.user_rating.aggregate_rating'].isna().sum()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\junke\\AppData\\Local\\Temp\\ipykernel_5932\\3470028770.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  filtered_rating_df['restaurant.user_rating.aggregate_rating'] = filtered_rating_df['restaurant.user_rating.aggregate_rating'].astype(\"float64\")\n"]}],"source":["\"\"\"\n","Changing the aggregate rating column to float data type\n","\"\"\"\n","\n","filtered_rating_df['restaurant.user_rating.aggregate_rating'] = filtered_rating_df['restaurant.user_rating.aggregate_rating'].astype(\"float64\")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["\"\"\"\n","Analyze the distribution of aggregate ratings for each rating text\n","\"\"\"\n","\n","aggregate = [ 'min', 'max']\n","\n","rating_statistics = filtered_rating_df.groupby('restaurant.user_rating.rating_text')['restaurant.user_rating.aggregate_rating'].agg(aggregate)\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["\"\"\"\n","Export rating_statistics to json\n","\"\"\"\n","\n","rating_statistics.to_json(input(), index=False)\n","\n","# My input was C:\\\\Users\\\\junke\\\\Desktop\\\\Important Documents (JunKeat)\\\\GovTech-Application\\\\restaurant_data.json"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["pd.set_option('display.max_columns', 500)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":2}
