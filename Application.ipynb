{"cells":[{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import json\n","import requests\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class RestaurantDataProcessor:\n","    def __init__(self, url, country_code_file, output_file_path):\n","        self.url = url\n","        self.country_code_file = country_code_file\n","        self.output_file_path = output_file_path\n","\n","    def fetch_json_data(self):\n","        try:\n","            response = requests.get(self.url)\n","            return response.json()\n","        except requests.exceptions.RequestException as e:\n","            print(f\"Error fetching restaurant data: {e}\")\n","            return None\n","\n","    def read_country_code_data(self):\n","        try:\n","            return pd.read_csv(self.country_code_file)\n","        except FileNotFoundError as e:\n","            print(f\"Error reading country code file: {e}\")\n","            return None\n","\n","    def merge_data(self, parsed_data, country_code_df):\n","        main_restaurant_df = pd.json_normalize(parsed_data, \"restaurants\")\n","        merged_df = pd.merge(\n","            main_restaurant_df, country_code_df, \n","            how='left', left_on='restaurant.location.country_id', \n","            right_on='Country Code'\n","        )\n","        return merged_df\n","\n","    def process_merged_data(self, merged_df):\n","        extract_restaurant_df = merged_df[[\n","            'restaurant.R.res_id', 'restaurant.name', 'Country', \n","            'restaurant.location.city', 'restaurant.user_rating.votes', \n","            'restaurant.user_rating.aggregate_rating', 'restaurant.cuisines'\n","        ]]\n","        renamed_columns = {\n","            'restaurant.R.res_id': 'Restaurant Id',\n","            'restaurant.name': 'Restaurant Name',\n","            'restaurant.location.city': 'City',\n","            'restaurant.user_rating.votes': 'User Rating Votes',\n","            'restaurant.user_rating.aggregate_rating': 'User Aggregate Rating',\n","            'restaurant.cuisines': 'Cuisines'\n","        }\n","        renamed_restaurant_df = extract_restaurant_df.rename(columns=renamed_columns)\n","        renamed_restaurant_df['User Aggregate Rating'] = renamed_restaurant_df['User Aggregate Rating'].astype('float64')\n","        final_restaurant_df = renamed_restaurant_df.dropna()\n","        return final_restaurant_df\n","\n","    def export_df_to_csv(self, df):\n","        try:\n","            df.to_csv(self.output_file_path, index=False)\n","            print(f\"Data exported successfully to {self.output_file_path}\")\n","        except Exception as e:\n","            print(f\"Error exporting data: {e}\")\n","\n","    def run(self):\n","        json_data = self.fetch_json_data()\n","        if json_data:\n","            country_code_df = self.read_country_code_data()\n","            merged_df = self.merge_data(json_data, country_code_df)\n","            final_df = self.process_merged_data(merged_df)\n","            self.export_df_to_csv(final_df)\n","        else:\n","            print(\"Failed to fetch or process data.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    url = \"https://raw.githubusercontent.com/Papagoat/brain-assessment/main/restaurant_data.json\"\n","    country_code_file = \"Country-Code.csv\"\n","    output_file_path = \"restaurants.csv\"\n","    processor = RestaurantDataProcessor(url, country_code_file, output_file_path)\n","    processor.run()"]},{"cell_type":"markdown","metadata":{},"source":["### Part 2"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["\"\"\"\n","Expanding the restaurant.zomato_events column \n","\"\"\"\n","\n","# Unpack the lists in the events column vertically\n","expended_events_df = main_restaurant_df.explode(\"restaurant.zomato_events\")\n","\n","# Unpack the dictionaries within each element of the column\n","unpacked_events_df = pd.json_normalize(expended_events_df[\"restaurant.zomato_events\"])\n","\n","# Merge the unpacked DataFrame with the original DataFrame\n","events_df = pd.concat([main_restaurant_df, unpacked_events_df], axis=1)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["\"\"\"\n","Filtering past event in the month of April 2019 \n","\"\"\"\n","\n","# Change event start and end date to a date data type\n","events_df['event.start_date'] = pd.to_datetime(events_df[\"event.start_date\"])\n","events_df['event.end_date'] = pd.to_datetime(events_df[\"event.end_date\"])\n","\n","\n","# Define the condition for events starting in or before April 2019\n","start_date_condition = (\n","    (events_df['event.start_date'].dt.year == 2019) & \n","    (events_df['event.start_date'].dt.month <= 4)\n",")\n","\n","# Define the condition for events ending in or after April 2019\n","end_date_condition = (\n","    (events_df['event.end_date'].dt.year == 2019) & \n","    (events_df['event.end_date'].dt.month >= 4)\n",")\n","\n","# Apply the conditions to filter the DataFrame\n","April2019_events_df = events_df[(start_date_condition | end_date_condition)]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["\"\"\"\n","Extraction and renaming of required columns\n","\"\"\"\n","\n","# Extract required Columns\n","April2019_events_df = April2019_events_df[[\n","    \"event.event_id\", \"restaurant.id\",\n","    \"restaurant.name\", \"restaurant.photos_url\",\n","    \"event.title\", \"event.start_date\",\n","    \"event.end_date\"\n","    ]]\n","\n","# Rename required columns\n","columns_to_rename = {\n","    \"event.event_id\":\"Event Id\", \n","    \"restaurant.id\":\"Restaurant Id\",\n","    \"restaurant.name\":\"Restaurant Name\", \n","    \"restaurant.photos_url\":\"Photo URL\",\n","    \"event.title\":\"Event Title\", \n","    \"event.start_date\":\"Event Start Date\",\n","    \"event.end_date\":\"Event End Date\"\n","}\n","\n","final_events_df = April2019_events_df.rename(columns=columns_to_rename)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","To check duplicate values\n","\"\"\"\n","\n","final_events_df.duplicated().sum()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["\"\"\"\n","Export final_events_df to CSV\n","\"\"\"\n","\n","final_events_df.to_csv(input(), index=False)\n","\n","# My input was C:\\\\Users\\\\junke\\\\Desktop\\\\Important Documents (JunKeat)\\\\GovTech-Application\\\\restaurant_events.csv"]},{"cell_type":"markdown","metadata":{},"source":["### Part 3"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["\"\"\"\n","Filter for the specified rating texts only\n","\"\"\"\n","\n","specified_texts = ['Excellent', 'Very Good', 'Good', 'Average', 'Poor']\n","filtered_rating_df = main_restaurant_df[main_restaurant_df['restaurant.user_rating.rating_text'].isin(specified_texts)]"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","To check for null values in the aggregate rating column\"\"\"\n","\n","filtered_rating_df['restaurant.user_rating.aggregate_rating'].isna().sum()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\junke\\AppData\\Local\\Temp\\ipykernel_5932\\3470028770.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  filtered_rating_df['restaurant.user_rating.aggregate_rating'] = filtered_rating_df['restaurant.user_rating.aggregate_rating'].astype(\"float64\")\n"]}],"source":["\"\"\"\n","Changing the aggregate rating column to float data type\n","\"\"\"\n","\n","filtered_rating_df['restaurant.user_rating.aggregate_rating'] = filtered_rating_df['restaurant.user_rating.aggregate_rating'].astype(\"float64\")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["\"\"\"\n","Analyze the distribution of aggregate ratings for each rating text\n","\"\"\"\n","\n","aggregate = [ 'min', 'max']\n","\n","rating_statistics = filtered_rating_df.groupby('restaurant.user_rating.rating_text')['restaurant.user_rating.aggregate_rating'].agg(aggregate)\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["\"\"\"\n","Export rating_statistics to json\n","\"\"\"\n","\n","rating_statistics.to_json(input(), index=False)\n","\n","# My input was C:\\\\Users\\\\junke\\\\Desktop\\\\Important Documents (JunKeat)\\\\GovTech-Application\\\\restaurant_data.json"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["pd.set_option('display.max_columns', 500)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":2}
